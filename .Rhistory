##This chunk is only needed when running on Jason's laptop.If it is on Jason's device change eval=TRUE
options("install.lock"=FALSE)
##Here we load the packages needed and install a package that is not on CRAN
library(ggplot2)
library(broom)
library(gridExtra)
library(class)
library(tidyverse)
library(gridExtra)
library(leaps)
library(corrplot)
library(RColorBrewer)
library(glmnet)
library(xtable)
library(randomForest)
library(tree)
library(pROC)
#library(smotefamily)
library(devtools)
library(UpSetR)
library(naniar)
library(report)
library(rpart)
library(rattle)
library(rpart.plot)
library(DataExplorer)
library(BART)
library(gbm)
ALZH<-read.csv("https://raw.githubusercontent.com/jasonh0509/StatsLearningFinal/refs/heads/main/alzheimers_disease_data.csv")
ALZH_noID<-ALZH[,-1]
ALZH_noID$Diagnosis<-as.factor(ALZH_noID$Diagnosis)
ALZH_noID <- ALZH_noID %>%
mutate(across(c(Gender, Ethnicity,EducationLevel,Smoking,FamilyHistoryAlzheimers,CardiovascularDisease,Diabetes,Depression,HeadInjury,Hypertension,MemoryComplaints,BehavioralProblems,Confusion,Disorientation,PersonalityChanges,DifficultyCompletingTasks,Forgetfulness), as.factor))
set.seed(12345)
ALZH.gbm.raw <- ALZH_noID %>% select(-DoctorInCharge) %>% mutate(Diagnosis = as.numeric(as.character(Diagnosis)))
ALZH.gbm <- ALZH.gbm.raw
boosting.try <- gbm(Diagnosis ~ ., data = ALZH.gbm[draw,], distribution = "bernoulli", n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)
ALZH_for_explore<-ALZH_noID%>%dplyr::select(-DoctorInCharge)
n <-nrow(ALZH_for_explore);n
set.seed(114514)
draw<-sample(1:n,size = 1934)
train <-ALZH_for_explore[draw,]
train_x<-train%>%dplyr::select(-Diagnosis)
train_y<-train%>%dplyr::select(Diagnosis)
test <- ALZH_for_explore[-draw,]
test_x<-test%>%dplyr::select(-Diagnosis)
test_y <-test$Diagnosis
x <-model.matrix(Diagnosis~.,data=ALZH_for_explore)
y <- ALZH_noID$Diagnosis
set.seed(12345)
ALZH.gbm.raw <- ALZH_noID %>% select(-DoctorInCharge) %>% mutate(Diagnosis = as.numeric(as.character(Diagnosis)))
ALZH.gbm <- ALZH.gbm.raw
boosting.try <- gbm(Diagnosis ~ ., data = ALZH.gbm[draw,], distribution = "bernoulli", n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)
set.seed(12345)
sample<- sample(1:nrow(ALZH.gbm),0.9 * nrow(ALZH.gbm))
ALZH.gbm.forTuning<-ALZH.gbm[sample,]
ALZH.gbm.realTest<-ALZH.gbm[-sample,]
set.seed(12345)
sample<- sample(1:nrow(ALZH.gbm),0.9 * nrow(ALZH.gbm))
ALZH.gbm.forTuning<-ALZH.gbm[sample,]
ALZH.gbm.realTest<-ALZH.gbm[-sample,]
set.seed(12345)
lambda_val <- seq(0.01, 0.03, by = 0.01)
ntree_val <- c(1000, 2000, 3000)
result<-c()
for (lambda in lambda_val) {
cat("Iteration: ", lambda, "\n")
for (ntree in ntree_val) {
cat("Iteration: ", ntree, "\n")
Recall_vals <- c()
Precision_vals <- c()
F1_score_vals <- c()
Accuracy_vals<-c()
for (f in 1:10) {
infold <- which(f == sample(rep(1:10,nrow(ALZH.gbm.forTuning))))
trainData <- ALZH.gbm.forTuning[-infold, ]
testData <- ALZH.gbm.forTuning[infold, ]
Boosting_alzh <- gbm(Diagnosis ~ ., data = trainData, distribution = "bernoulli", n.trees = ntree, interaction.depth = 4, shrinkage = lambda)
pred <- predict(Boosting_alzh, newdata = testData, n.trees = ntree, type = "response")
pred_class <- ifelse(pred > 0.5, 1, 0)
TP <- sum(pred_class == 1 & testData$Diagnosis == 1)
FP <- sum(pred_class == 1 & testData$Diagnosis == 0)
FN <- sum(pred_class == 0 & testData$Diagnosis == 1)
Recall <- TP / (TP + FN)
Precision <- TP / (TP + FP)
F1_score<- 2 * (Precision * Recall) / (Precision + Recall)
Accuracy<-sum(pred_class == testData$Diagnosis)/length(testData$Diagnosis)
Recall_vals <- c(Recall_vals, Recall)
Precision_vals <- c(Precision_vals, Precision)
F1_score_vals <- c(F1_score_vals, F1_score)
Accuracy_vals<-c(Accuracy_vals,Accuracy)
}
result <- rbind(result, data.frame(Lambda = lambda, NTree = ntree, Recall = mean(Recall_vals), Precision = mean(Precision_vals), F1_Score = mean(F1_score_vals),Accuracy=mean(Accuracy_vals)))
}
}
best_result <- result[which.max(result$Recall), ]
best_result
plot(result$Lambda, result$F1_Score, xlab = "Lambda", ylab = "F1 Score", type = "l", col = "blue")
View(best_result)
set.seed(12345)
Boosting_alzh.final<-gbm(Diagnosis~.,data=ALZH.gbm[draw,],distribution="bernoulli",n.trees=2000,interaction.depth=4,shrinkage=0.01)
yhat.boost.final<-predict(Boosting_alzh.final,newdata = ALZH.gbm[-draw,],n.trees = 2000,interaction.depth = 4,shrinkage = 0.01,type = "response")
pred_gbm_class_final <- ifelse(yhat.boost.final > 0.5, 1, 0)
table(pred_gbm_class_final,ALZH.gbm[-draw,]$Diagnosis)
set.seed(12345)
Boosting_alzh.final<-gbm(Diagnosis~.,data=ALZH.gbm.forTuning,distribution="bernoulli",n.trees=2000,interaction.depth=4,shrinkage=0.01)
yhat.boost.final<-predict(Boosting_alzh.final,newdata = ALZH.gbm.realTest,n.trees = 2000,interaction.depth = 4,shrinkage = 0.01,type = "response")
pred_gbm_class_final <- ifelse(yhat.boost.final > 0.5, 1, 0)
table(pred_gbm_class_final,ALZH.gbm[-draw,]$Diagnosis)
set.seed(12345)
lambda_val <- seq(0.01, 0.03, by = 0.01)
result_container <- data.frame(Lambda = lambda_val, Recall = rep(0, length(lambda_val)), Precision = rep(0, length(lambda_val)), F1_Score = rep(0, length(lambda_val)))
for (i in 1:length(lambda_val)) {
Boosting_alzh <- gbm(Diagnosis ~., data = ALZH.gbm.forTuning, distribution = "bernoulli", n.trees = 2000, interaction.depth = 4, shrinkage = lambda_val[i])
pred <- predict(Boosting_alzh, newdata = ALZH.gbm[-draw,], n.trees = 2000, type = "response")
pred_class <- ifelse(pred > 0.5, 1, 0)
tp <- sum(pred_class == 1 & ALZH.gbm[-draw,]$Diagnosis == 1)
fp <- sum(pred_class == 1 & ALZH.gbm[-draw,]$Diagnosis == 0)
fn <- sum(pred_class == 0 & ALZH.gbm[-draw,]$Diagnosis == 1)
recall <- tp / (tp + fn)
precision <- tp / (tp + fp)
f1_score <- 2 * (precision * recall) / (precision + recall)
result_container$Recall[i] <- recall
result_container$Precision[i] <- precision
result_container$F1_Score[i] <- f1_score
}
plot(x = result_container$Lambda, y = result_container$F1_Score, xlab = "Lambda", ylab = "F1 Score", type = "l")
View(result_container)
